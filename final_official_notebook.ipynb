{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bf36ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import math\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cedacdab",
   "metadata": {},
   "source": [
    "Set device and config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb370a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU Count: {torch.cuda.device_count()}\")\n",
    "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "# Speed-optimized configuration for ~5 min per epoch\n",
    "CONFIG = {\n",
    "    'data_path': '/kaggle/input/nii-larger-dataset/DATASET_NIFTI2',\n",
    "    'image_size': 224,      # Reduced from 260 for faster processing\n",
    "    'num_slices': 16,       # Reduced from 20 to decrease total samples\n",
    "    'batch_size': 32,       # Increased from 16 for fewer iterations\n",
    "    'num_epochs': 35,\n",
    "    'learning_rate': 3e-4,\n",
    "    'num_classes': 3,\n",
    "    'patience': 12,\n",
    "    'weight_decay': 0.01,\n",
    "    'label_smoothing': 0.1,\n",
    "    'T_max': 10,\n",
    "}\n",
    "\n",
    "class_names = ['AD', 'CN', 'MCI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7f8e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelSmoothingCrossEntropy(nn.Module):\n",
    "    def __init__(self, smoothing=0.1):\n",
    "        super(LabelSmoothingCrossEntropy, self).__init__()\n",
    "        self.smoothing = smoothing\n",
    "    \n",
    "    def forward(self, x, target):\n",
    "        confidence = 1. - self.smoothing\n",
    "        logprobs = torch.nn.functional.log_softmax(x, dim=-1)\n",
    "        nll_loss = -logprobs.gather(dim=-1, index=target.unsqueeze(1))\n",
    "        nll_loss = nll_loss.squeeze(1)\n",
    "        smooth_loss = -logprobs.mean(dim=-1)\n",
    "        loss = confidence * nll_loss + self.smoothing * smooth_loss\n",
    "        return loss.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3290a6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SEBlock(nn.Module):\n",
    "    def __init__(self, channels, reduction=16):\n",
    "        super(SEBlock, self).__init__()\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc1 = nn.Linear(channels, channels // reduction, bias=False)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.fc2 = nn.Linear(channels // reduction, channels, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        b, c, _, _ = x.size()\n",
    "        y = self.avgpool(x).view(b, c)\n",
    "        y = self.fc1(y)\n",
    "        y = self.relu(y)\n",
    "        y = self.fc2(y)\n",
    "        y = self.sigmoid(y).view(b, c, 1, 1)\n",
    "        return x * y.expand_as(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fabe5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnhancedMRISliceDataset(Dataset):\n",
    "    def __init__(self, samples, transform=None):\n",
    "        self.samples = samples\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        path, label, slice_idx = self.samples[idx]\n",
    "        \n",
    "        img = nib.load(path).get_fdata()\n",
    "        \n",
    "        if slice_idx < img.shape[2]:\n",
    "            slice_2d = img[:, :, slice_idx]\n",
    "        else:\n",
    "            slice_2d = img[:, :, img.shape[2]//2]\n",
    "        \n",
    "        # Enhanced normalization for intensity. \n",
    "        p2, p98 = np.percentile(slice_2d, (2, 98))\n",
    "        slice_2d = np.clip(slice_2d, p2, p98)\n",
    "        slice_2d = (slice_2d - slice_2d.min()) / (slice_2d.max() - slice_2d.min() + 1e-8)\n",
    "        \n",
    "        slice_2d = np.stack([slice_2d, slice_2d, slice_2d], axis=2)\n",
    "        slice_2d = (slice_2d * 255).astype(np.uint8)\n",
    "        \n",
    "        if self.transform:\n",
    "            slice_2d = self.transform(slice_2d)\n",
    "        \n",
    "        return slice_2d, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebeeaa98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_key_slices(nii_path, num_slices=16):\n",
    "    img = nib.load(nii_path).get_fdata()\n",
    "    total_slices = img.shape[2]\n",
    "    \n",
    "    # Optimized slice selection for faster processing\n",
    "    start_slice = int(total_slices * 0.15)\n",
    "    end_slice = int(total_slices * 0.85)\n",
    "    \n",
    "    slice_indices = np.linspace(start_slice, end_slice-1, num_slices, dtype=int)\n",
    "    return slice_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76469540",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_dataset():\n",
    "    print(\"Creating enhanced dataset...\")\n",
    "    \n",
    "    all_samples = []\n",
    "    class_counts = {}\n",
    "    \n",
    "    for class_idx, class_name in enumerate(class_names):\n",
    "        class_path = os.path.join(CONFIG['data_path'], class_name)\n",
    "        nii_files = [f for f in os.listdir(class_path) if f.endswith('.nii')]\n",
    "        \n",
    "        print(f\"Processing {len(nii_files)} files for {class_name}\")\n",
    "        class_counts[class_name] = len(nii_files)\n",
    "        \n",
    "        for file in tqdm(nii_files, desc=f\"Loading {class_name}\"):\n",
    "            file_path = os.path.join(class_path, file)\n",
    "            \n",
    "            try:\n",
    "                slice_indices = extract_key_slices(file_path, CONFIG['num_slices'])\n",
    "                \n",
    "                for slice_idx in slice_indices:\n",
    "                    all_samples.append((file_path, class_idx, slice_idx))\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {file}: {e}\")\n",
    "                continue\n",
    "    \n",
    "    print(f\"Total samples: {len(all_samples)}\")\n",
    "    print(f\"Class distribution: {class_counts}\")\n",
    "    return all_samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58930529",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class EfficientNetB2WithSE(nn.Module):\n",
    "    def __init__(self, num_classes=3):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Load pre-trained EfficientNetB2  \n",
    "        try:\n",
    "            from torchvision.models import efficientnet_b2, EfficientNet_B2_Weights\n",
    "            self.backbone = efficientnet_b2(weights=EfficientNet_B2_Weights.IMAGENET1K_V1)\n",
    "        except ImportError:\n",
    "            self.backbone = models.efficientnet_b2(pretrained=True)\n",
    "        \n",
    "        # Get features\n",
    "        num_features = self.backbone.classifier[1].in_features\n",
    "        self.backbone.classifier = nn.Identity()\n",
    "        \n",
    "        # Lighter SE block for speed\n",
    "        self.se_block = SEBlock(num_features, reduction=8)  # Reduced from 16\n",
    "        \n",
    "        # Simplified classifier for faster training\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(num_features, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Extract features\n",
    "        features = self.backbone.features(x)\n",
    "        \n",
    "        # Global pooling\n",
    "        features = nn.AdaptiveAvgPool2d(1)(features)\n",
    "        \n",
    "        # SE attention\n",
    "        features = self.se_block(features)\n",
    "        \n",
    "        # Flatten and classify\n",
    "        features = features.flatten(1)\n",
    "        return self.classifier(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53da2b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CosineAnnealingWarmupRestarts(optim.lr_scheduler._LRScheduler):\n",
    "    def __init__(self, optimizer, T_max, eta_min=0, T_mult=1, last_epoch=-1):\n",
    "        self.T_max = T_max\n",
    "        self.eta_min = eta_min\n",
    "        self.T_mult = T_mult\n",
    "        self.T_cur = 0\n",
    "        super(CosineAnnealingWarmupRestarts, self).__init__(optimizer, last_epoch)\n",
    "    \n",
    "    def get_lr(self):\n",
    "        return [self.eta_min + (base_lr - self.eta_min) * \n",
    "                (1 + math.cos(math.pi * self.T_cur / self.T_max)) / 2\n",
    "                for base_lr in self.base_lrs]\n",
    "    \n",
    "    def step(self, epoch=None):\n",
    "        if epoch is None:\n",
    "            epoch = self.last_epoch + 1\n",
    "        self.T_cur = epoch % self.T_max\n",
    "        super(CosineAnnealingWarmupRestarts, self).step(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcbf6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_model(model, train_loader, val_loader):\n",
    "    model = model.to(device)\n",
    "    \n",
    "    criterion = LabelSmoothingCrossEntropy(smoothing=CONFIG['label_smoothing'])\n",
    "    optimizer = optim.AdamW(model.parameters(), \n",
    "                           lr=CONFIG['learning_rate'], \n",
    "                           weight_decay=CONFIG['weight_decay'])\n",
    "    \n",
    "    scheduler = CosineAnnealingWarmupRestarts(optimizer, T_max=CONFIG['T_max'])\n",
    "    \n",
    "    best_val_acc = 0\n",
    "    patience_counter = 0\n",
    "    \n",
    "    train_accs = []\n",
    "    val_accs = []\n",
    "    train_losses = []\n",
    "    \n",
    "    for epoch in range(CONFIG['num_epochs']):\n",
    "        # Training\n",
    "        model.train()\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        train_loss = 0\n",
    "        \n",
    "        for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            \n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            train_total += labels.size(0)\n",
    "            train_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        train_acc = 100.0 * train_correct / train_total\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        val_loss = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                \n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        val_acc = 100.0 * val_correct / val_total\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        \n",
    "        train_accs.append(train_acc)\n",
    "        val_accs.append(val_acc)\n",
    "        train_losses.append(avg_train_loss)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{CONFIG['num_epochs']}\")\n",
    "        print(f\"Train Loss: {avg_train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
    "        print(f\"Val Loss: {avg_val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
    "        print(f\"LR: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "        \n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            patience_counter = 0\n",
    "            torch.save(model.state_dict(), 'best_alzheimer_efficientnet.pth')\n",
    "            print(f\"âœ“ New best model! Val Acc: {best_val_acc:.2f}%\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "        \n",
    "        if patience_counter >= CONFIG['patience']:\n",
    "            print(f\"Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "        \n",
    "        scheduler.step()\n",
    "        print(\"-\" * 60)\n",
    "    \n",
    "    model.load_state_dict(torch.load('best_alzheimer_efficientnet.pth'))\n",
    "    return train_accs, val_accs, train_losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4ac308",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_per_volume(model, test_samples):\n",
    "    model.eval()\n",
    "    \n",
    "    volume_predictions = {}\n",
    "    volume_labels = {}\n",
    "    \n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize((CONFIG['image_size'], CONFIG['image_size'])),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for path, label, slice_idx in tqdm(test_samples, desc=\"Evaluating\"):\n",
    "            img = nib.load(path).get_fdata()\n",
    "            if slice_idx < img.shape[2]:\n",
    "                slice_2d = img[:, :, slice_idx]\n",
    "            else:\n",
    "                slice_2d = img[:, :, img.shape[2]//2]\n",
    "            \n",
    "            p2, p98 = np.percentile(slice_2d, (2, 98))\n",
    "            slice_2d = np.clip(slice_2d, p2, p98)\n",
    "            slice_2d = (slice_2d - slice_2d.min()) / (slice_2d.max() - slice_2d.min() + 1e-8)\n",
    "            slice_2d = np.stack([slice_2d, slice_2d, slice_2d], axis=2)\n",
    "            slice_2d = (slice_2d * 255).astype(np.uint8)\n",
    "            \n",
    "            slice_tensor = transform(slice_2d).unsqueeze(0).to(device)\n",
    "            \n",
    "            output = model(slice_tensor)\n",
    "            prob = torch.softmax(output, dim=1).cpu().numpy()[0]\n",
    "            \n",
    "            if path not in volume_predictions:\n",
    "                volume_predictions[path] = []\n",
    "                volume_labels[path] = label\n",
    "            \n",
    "            volume_predictions[path].append(prob)\n",
    "    \n",
    "    final_predictions = []\n",
    "    final_labels = []\n",
    "    \n",
    "    for path in volume_predictions:\n",
    "        avg_prob = np.mean(volume_predictions[path], axis=0)\n",
    "        pred_class = np.argmax(avg_prob)\n",
    "        \n",
    "        final_predictions.append(pred_class)\n",
    "        final_labels.append(volume_labels[path])\n",
    "    \n",
    "    return final_predictions, final_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230e263c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main():\n",
    "    print(\"=\" * 60)\n",
    "    print(\"ðŸ§  ENHANCED ALZHEIMER'S CLASSIFICATION - BALANCED DATASET (TARGET: >90%)\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    all_samples = create_dataset()\n",
    "    \n",
    "    train_samples, test_samples = train_test_split(all_samples, test_size=0.2, random_state=42)\n",
    "    train_samples, val_samples = train_test_split(train_samples, test_size=0.2, random_state=42)\n",
    "    \n",
    "    print(f\"Train: {len(train_samples)}, Val: {len(val_samples)}, Test: {len(test_samples)}\")\n",
    "    \n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize((CONFIG['image_size'], CONFIG['image_size'])),\n",
    "        transforms.RandomHorizontalFlip(0.5),\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "        transforms.RandomAffine(degrees=10, translate=(0.1, 0.1)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize((CONFIG['image_size'], CONFIG['image_size'])),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    train_dataset = EnhancedMRISliceDataset(train_samples, train_transform)\n",
    "    val_dataset = EnhancedMRISliceDataset(val_samples, val_transform)\n",
    "    \n",
    "    # Faster data loading with more workers\n",
    "    train_loader = DataLoader(train_dataset, batch_size=CONFIG['batch_size'], \n",
    "                             shuffle=True, num_workers=4, pin_memory=True, \n",
    "                             persistent_workers=True, prefetch_factor=2)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=CONFIG['batch_size']*2, \n",
    "                           shuffle=False, num_workers=4, pin_memory=True,\n",
    "                           persistent_workers=True, prefetch_factor=2)\n",
    "    \n",
    "    model = EfficientNetB2WithSE(CONFIG['num_classes'])\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"Total parameters: {total_params:,}\")\n",
    "    print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "    \n",
    "    print(\"Starting enhanced training...\")\n",
    "    train_accs, val_accs, train_losses = train_model(model, train_loader, val_loader)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    \n",
    "    axes[0].plot(train_accs, label='Train', color='blue')\n",
    "    axes[0].plot(val_accs, label='Validation', color='red')\n",
    "    axes[0].set_title('Accuracy Progress')\n",
    "    axes[0].set_xlabel('Epoch')\n",
    "    axes[0].set_ylabel('Accuracy (%)')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True)\n",
    "    \n",
    "    axes[1].plot(train_losses, label='Train Loss', color='green')\n",
    "    axes[1].set_title('Training Loss')\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].set_ylabel('Loss')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True)\n",
    "    \n",
    "    axes[2].axhline(y=90, color='red', linestyle='--', label='90% Target')\n",
    "    axes[2].plot(val_accs, label='Validation Accuracy', color='red')\n",
    "    axes[2].set_title('Validation Accuracy vs Target')\n",
    "    axes[2].set_xlabel('Epoch')\n",
    "    axes[2].set_ylabel('Accuracy (%)')\n",
    "    axes[2].legend()\n",
    "    axes[2].grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Enhanced evaluation on test set...\")\n",
    "    test_predictions, test_labels = evaluate_per_volume(model, test_samples)\n",
    "    \n",
    "    accuracy = accuracy_score(test_labels, test_predictions)\n",
    "    print(f\"\\nðŸŽ¯ ENHANCED RESULTS\")\n",
    "    print(f\"Test Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "    \n",
    "    if accuracy >= 0.90:\n",
    "        print(\"ðŸŽ‰ TARGET ACHIEVED: >90% ACCURACY!\")\n",
    "    else:\n",
    "        print(f\"ðŸ“Š Progress: {accuracy*100:.2f}% (Target: 90%)\")\n",
    "    \n",
    "    print(\"\\nDetailed Classification Report:\")\n",
    "    print(classification_report(test_labels, test_predictions, target_names=class_names))\n",
    "    \n",
    "    return model, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5274285",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    model, accuracy = main()\n",
    "    print(f\"\\nðŸš€ Enhanced training complete! Final accuracy: {accuracy*100:.2f}%\")\n",
    "    \n",
    "    if accuracy >= 0.90:\n",
    "        print(\"âœ… MISSION ACCOMPLISHED: >90% ACCURACY ACHIEVED!\")\n",
    "    else:\n",
    "        print(f\"ðŸ“ˆ Current: {accuracy*100:.2f}% | Target: 90%\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
